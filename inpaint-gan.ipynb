{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11944697,"sourceType":"datasetVersion","datasetId":7509085},{"sourceId":11945067,"sourceType":"datasetVersion","datasetId":7509326}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.models import vgg16, VGG16_Weights\nfrom torchvision.transforms import ToTensor, Normalize, Compose, Resize\nfrom PIL import Image\nimport numpy as np\nimport os\nimport glob\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T08:14:09.70007Z","iopub.execute_input":"2025-05-26T08:14:09.700239Z","iopub.status.idle":"2025-05-26T08:14:16.745403Z","shell.execute_reply.started":"2025-05-26T08:14:09.700221Z","shell.execute_reply":"2025-05-26T08:14:16.744644Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T08:14:16.746904Z","iopub.execute_input":"2025-05-26T08:14:16.74723Z","iopub.status.idle":"2025-05-26T08:14:16.815057Z","shell.execute_reply.started":"2025-05-26T08:14:16.747213Z","shell.execute_reply":"2025-05-26T08:14:16.814339Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_dir = \"output\"\nos.makedirs(output_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T08:14:16.815927Z","iopub.execute_input":"2025-05-26T08:14:16.816199Z","iopub.status.idle":"2025-05-26T08:14:16.835116Z","shell.execute_reply.started":"2025-05-26T08:14:16.816177Z","shell.execute_reply":"2025-05-26T08:14:16.834573Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class UNetGenerator(nn.Module):\n    def __init__(self, in_channels=1, out_channels=1):\n        super(UNetGenerator, self).__init__()\n        def conv_block(in_c, out_c):\n            return nn.Sequential(\n                nn.Conv2d(in_c, out_c, 3, padding=1),\n                nn.BatchNorm2d(out_c),\n                nn.ReLU(inplace=True),\n                nn.Conv2d(out_c, out_c, 3, padding=1),\n                nn.BatchNorm2d(out_c),\n                nn.ReLU(inplace=True)\n            )\n        \n        self.encoder1 = conv_block(in_channels, 64)\n        self.encoder2 = conv_block(64, 128)\n        self.encoder3 = conv_block(128, 256)\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        self.bottleneck = conv_block(256, 512)\n        \n        self.upconv3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n        self.decoder3 = conv_block(512, 256)\n        self.upconv2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n        self.decoder2 = conv_block(256, 128)\n        self.upconv1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n        self.decoder1 = conv_block(128, 64)\n        \n        self.final_conv = nn.Conv2d(64, out_channels, 1)\n    \n    def forward(self, x):\n        e1 = self.encoder1(x)\n        e2 = self.encoder2(self.pool(e1))\n        e3 = self.encoder3(self.pool(e2))\n        b = self.bottleneck(self.pool(e3))\n        d3 = self.upconv3(b)\n        d3 = torch.cat([d3, e3], dim=1)\n        d3 = self.decoder3(d3)\n        d2 = self.upconv2(d3)\n        d2 = torch.cat([d2, e2], dim=1)\n        d2 = self.decoder2(d2)\n        d1 = self.upconv1(d2)\n        d1 = torch.cat([d1, e1], dim=1)\n        d1 = self.decoder1(d1)\n        return torch.tanh(self.final_conv(d1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T08:14:16.835842Z","iopub.execute_input":"2025-05-26T08:14:16.836062Z","iopub.status.idle":"2025-05-26T08:14:16.850508Z","shell.execute_reply.started":"2025-05-26T08:14:16.836041Z","shell.execute_reply":"2025-05-26T08:14:16.849811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class PatchDiscriminator(nn.Module):\n    def __init__(self, in_channels=1):\n        super(PatchDiscriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(in_channels, 64, 4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(256, 1, 4, padding=1),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        return self.model(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T08:14:16.852178Z","iopub.execute_input":"2025-05-26T08:14:16.852382Z","iopub.status.idle":"2025-05-26T08:14:16.869156Z","shell.execute_reply.started":"2025-05-26T08:14:16.852366Z","shell.execute_reply":"2025-05-26T08:14:16.868456Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class LossFunctions:\n    def __init__(self):\n        self.bce = nn.BCELoss()\n        self.l1 = nn.L1Loss()\n        self.vgg = vgg16(weights=VGG16_Weights.IMAGENET1K_V1).features.to(device).eval()\n        for param in self.vgg.parameters():\n            param.requires_grad = False\n    \n    def adversarial_loss(self, pred, target):\n        return self.bce(pred, target)\n    \n    def pixel_loss(self, pred, target):\n        return self.l1(pred, target)\n    \n    def perceptual_loss(self, pred, target):\n        pred_features = self.vgg(pred.repeat(1, 3, 1, 1))\n        target_features = self.vgg(target.repeat(1, 3, 1, 1))\n        return self.l1(pred_features, target_features)\n    \n    def style_loss(self, pred, target):\n        def gram_matrix(x):\n            b, c, h, w = x.size()\n            x = x.view(b, c, h * w)\n            return torch.bmm(x, x.transpose(1, 2)) / (c * h * w)\n        \n        pred_gram = gram_matrix(self.vgg(pred.repeat(1, 3, 1, 1)))\n        target_gram = gram_matrix(self.vgg(target.repeat(1, 3, 1, 1)))\n        return self.l1(pred_gram, target_gram)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T08:14:16.869943Z","iopub.execute_input":"2025-05-26T08:14:16.870572Z","iopub.status.idle":"2025-05-26T08:14:16.887098Z","shell.execute_reply.started":"2025-05-26T08:14:16.870554Z","shell.execute_reply":"2025-05-26T08:14:16.886577Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MedicalImageDataset(Dataset):\n    def __init__(self, infected_dir, gt_dir, transform=None):\n        self.infected_dir = infected_dir\n        self.gt_dir = gt_dir\n        self.transform = transform\n        \n        # Tải danh sách file\n        self.infected_files = sorted(glob.glob(os.path.join(infected_dir, \"*.png\")))\n        self.gt_files = sorted(glob.glob(os.path.join(gt_dir, \"*.png\")))\n        \n        # Kiểm tra dataset\n        if not self.infected_files or not self.gt_files:\n            raise ValueError(f\"No images found in {infected_dir} or {gt_dir}\")\n        if len(self.infected_files) != len(self.gt_files):\n            raise ValueError(f\"Mismatch in number of images: {len(self.infected_files)} in infected, {len(self.gt_files)} in ground truth\")\n        \n        # Kiểm tra tên file có khớp không\n        for inf, gt in zip(self.infected_files, self.gt_files):\n            if os.path.basename(inf) != os.path.basename(gt):\n                raise ValueError(f\"File names do not match: {inf} vs {gt}\")\n        \n        print(f\"Loaded {len(self.infected_files)} image pairs\")\n    \n    def __len__(self):\n        return len(self.infected_files)\n    \n    def __getitem__(self, idx):\n        try:\n            infected_img = Image.open(self.infected_files[idx]).convert('L')\n            gt_img = Image.open(self.gt_files[idx]).convert('L')\n        except FileNotFoundError as e:\n            raise FileNotFoundError(f\"Error loading image: {self.infected_files[idx]} or {self.gt_files[idx]}\") from e\n        \n        if self.transform:\n            infected_img = self.transform(infected_img)\n            gt_img = self.transform(gt_img)\n        \n        return infected_img, gt_img, os.path.basename(self.infected_files[idx])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T08:14:16.887802Z","iopub.execute_input":"2025-05-26T08:14:16.888047Z","iopub.status.idle":"2025-05-26T08:14:16.900955Z","shell.execute_reply.started":"2025-05-26T08:14:16.888024Z","shell.execute_reply":"2025-05-26T08:14:16.900355Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_images(infected_img, restored_img, gt_img, filename, output_dir):\n    # Detach để ngắt gradient tracking trước khi chuyển sang\n    infected_img = (infected_img * 0.5 + 0.5).clamp(0, 1).detach().squeeze().cpu().numpy()\n    restored_img = (restored_img * 0.5 + 0.5).clamp(0, 1).detach().squeeze().cpu().numpy()\n    gt_img = (gt_img * 0.5 + 0.5).clamp(0, 1).detach().squeeze().cpu().numpy()\n    \n    sample_dir = os.path.join(output_dir, \"samples\")\n    os.makedirs(sample_dir, exist_ok=True)\n    \n    base_name = os.path.splitext(filename)[0]\n    Image.fromarray((infected_img * 255).astype(np.uint8)).save(\n        os.path.join(sample_dir, f\"{base_name}_infected.png\"))\n    Image.fromarray((restored_img * 255).astype(np.uint8)).save(\n        os.path.join(sample_dir, f\"{base_name}_restored.png\"))\n    Image.fromarray((gt_img * 255).astype(np.uint8)).save(\n        os.path.join(sample_dir, f\"{base_name}_ground_truth.png\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T08:14:16.901558Z","iopub.execute_input":"2025-05-26T08:14:16.901794Z","iopub.status.idle":"2025-05-26T08:14:16.919416Z","shell.execute_reply.started":"2025-05-26T08:14:16.901778Z","shell.execute_reply":"2025-05-26T08:14:16.918781Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(generator, disc1, disc2, dataloader, num_epochs=300, save_samples=5):\n    loss_fn = LossFunctions()\n    g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n    d_optimizer = optim.Adam(list(disc1.parameters()) + list(disc2.parameters()), lr=0.0002, betas=(0.5, 0.999))\n    \n    lambda_adv, lambda_pixel, lambda_perc, lambda_style = 1.0, 100.0, 10.0, 250.0\n    best_g_loss = float('inf')\n    \n    for epoch in range(num_epochs):\n        total_g_loss = 0.0\n        total_d_loss = 0.0\n        num_batches = 0\n        \n        for i, (infected, gt, filename) in enumerate(dataloader):\n            infected, gt = infected.to(device), gt.to(device)\n            \n            # Huấn luyện Discriminators\n            d_optimizer.zero_grad()\n            fake = generator(infected)\n            \n            real_d1 = disc1(gt)\n            fake_d1 = disc1(fake.detach())\n            real_d2 = disc2(gt)\n            fake_d2 = disc2(fake.detach())\n            \n            d_loss = (loss_fn.adversarial_loss(real_d1, torch.ones_like(real_d1)) +\n                      loss_fn.adversarial_loss(fake_d1, torch.zeros_like(fake_d1)) +\n                      loss_fn.adversarial_loss(real_d2, torch.ones_like(real_d2)) +\n                      loss_fn.adversarial_loss(fake_d2, torch.zeros_like(fake_d2))) / 4\n            \n            d_loss.backward()\n            d_optimizer.step()\n            \n            # Huấn luyện Generator\n            g_optimizer.zero_grad()\n            fake = generator(infected)\n            fake_d1 = disc1(fake)\n            fake_d2 = disc2(fake)\n            \n            g_adv_loss = (loss_fn.adversarial_loss(fake_d1, torch.ones_like(fake_d1)) +\n                          loss_fn.adversarial_loss(fake_d2, torch.ones_like(fake_d2))) / 2\n            g_pixel_loss = loss_fn.pixel_loss(fake, gt)\n            g_perc_loss = loss_fn.perceptual_loss(fake, gt)\n            g_style_loss = loss_fn.style_loss(fake, gt)\n            \n            g_loss = (lambda_adv * g_adv_loss + lambda_pixel * g_pixel_loss +\n                      lambda_perc * g_perc_loss + lambda_style * g_style_loss)\n            \n            g_loss.backward()\n            g_optimizer.step()\n            \n            total_g_loss += g_loss.item()\n            total_d_loss += d_loss.item()\n            num_batches += 1\n            \n            # Lưu ảnh mẫu cho một số batch đầu tiên\n            if i < save_samples:\n                save_images(infected[0], fake[0], gt[0], filename[0], output_dir)\n            \n            if i % 10 == 0:\n                print(f\"Epoch [{epoch+1}/{num_epochs}] Batch [{i+1}/{len(dataloader)}] \"\n                      f\"D Loss: {d_loss.item():.4f} G Loss: {g_loss.item():.4f}\")\n        \n        # Tính mất mát trung bình\n        avg_g_loss = total_g_loss / num_batches\n        avg_d_loss = total_d_loss / num_batches\n        print(f\"Epoch [{epoch+1}/{num_epochs}] Avg D Loss: {avg_d_loss:.4f} Avg G Loss: {avg_g_loss:.4f}\")\n        \n        # Lưu mô hình nếu mất mát Generator cải thiện\n        if avg_g_loss < best_g_loss:\n            best_g_loss = avg_g_loss\n            torch.save(generator.state_dict(), os.path.join(output_dir, \"best_generator.pth\"))\n            print(f\"Saved best model at epoch {epoch+1} with G Loss: {avg_g_loss:.4f}\")\n    \n    # Lưu mô hình cuối cùng\n    torch.save(generator.state_dict(), os.path.join(output_dir, \"final_generator.pth\"))\n    return generator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T08:14:16.920015Z","iopub.execute_input":"2025-05-26T08:14:16.920196Z","iopub.status.idle":"2025-05-26T08:14:16.942115Z","shell.execute_reply.started":"2025-05-26T08:14:16.920175Z","shell.execute_reply":"2025-05-26T08:14:16.941638Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"infected_dir = \"/kaggle/input/tumor-injection-attack/ATTACKED\"  \ngt_dir = \"/kaggle/input/axial-mri-norm\"  \n\n# Kiểm tra thư mục tồn tại\nif not os.path.exists(infected_dir) or not os.path.exists(gt_dir):\n    raise FileNotFoundError(f\"Dataset directories not found: {infected_dir} or {gt_dir}\")\n\n# Transform cho ảnh\ntransform = Compose([\n    Resize((128, 128)),  # Thay đổi kích thước thành 256x256\n    ToTensor(),\n    Normalize(mean=[0.5], std=[0.5])\n])\n\n# Tạo dataset và dataloader\ntry:\n    dataset = MedicalImageDataset(infected_dir, gt_dir, transform)\nexcept ValueError as e:\n    print(f\"Error creating dataset: {e}\")\n    exit(1)\n\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n\n# Khởi tạo mô hình\ngenerator = UNetGenerator(in_channels=1, out_channels=1).to(device)\ndisc1 = PatchDiscriminator(in_channels=1).to(device)\ndisc2 = PatchDiscriminator(in_channels=1).to(device)\n\n# Huấn luyện\ngenerator = train_model(generator, disc1, disc2, dataloader, num_epochs=200, save_samples=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T08:14:16.942804Z","iopub.execute_input":"2025-05-26T08:14:16.943043Z","iopub.status.idle":"2025-05-26T11:19:07.67702Z","shell.execute_reply.started":"2025-05-26T08:14:16.943022Z","shell.execute_reply":"2025-05-26T11:19:07.676204Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"def save_and_display_images(infected_img, restored_img, filename, output_dir):\n    # Denormalize và chuyển sang numpy\n    infected_img = (infected_img * 0.5 + 0.5).clamp(0, 1).squeeze().cpu().numpy()\n    restored_img = (restored_img * 0.5 + 0.5).clamp(0, 1).squeeze().cpu().numpy()\n    \n    # Tạo thư mục đầu ra\n    os.makedirs(output_dir, exist_ok=True)\n    \n    # Lưu ảnh\n    base_name = os.path.splitext(os.path.basename(filename))[0]\n    Image.fromarray((infected_img * 255).astype(np.uint8)).save(\n        os.path.join(output_dir, f\"{base_name}_infected.png\"))\n    Image.fromarray((restored_img * 255).astype(np.uint8)).save(\n        os.path.join(output_dir, f\"{base_name}_restored.png\"))\n    print(f\"Images saved to {output_dir}: {base_name}_infected.png, {base_name}_restored.png\")\n    \n    # Hiển thị ảnh\n    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n    axes[0].imshow(infected_img, cmap='gray')\n    axes[0].set_title(\"Infected Image\")\n    axes[0].axis('off')\n    axes[1].imshow(restored_img, cmap='gray')\n    axes[1].set_title(\"Restored Image\")\n    axes[1].axis('off')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T11:27:59.940118Z","iopub.execute_input":"2025-05-26T11:27:59.94081Z","iopub.status.idle":"2025-05-26T11:27:59.949719Z","shell.execute_reply.started":"2025-05-26T11:27:59.94078Z","shell.execute_reply":"2025-05-26T11:27:59.948891Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"weights_path = \"/kaggle/working/output/best_generator.pth\"  \ninfected_image_path = \"/kaggle/input/tumor-injection-attack/ATTACKED/sub-BrainAge000129_T1w_axial_center.png\"  # Thay bằng đường dẫn thực\noutput_dir = \"/kaggle/working/output/restored\"\n\nif not os.path.exists(weights_path):\n    raise FileNotFoundError(f\"Weights file not found: {weights_path}\")\nif not os.path.exists(infected_image_path):\n    raise FileNotFoundError(f\"Image file not found: {infected_image_path}\")\n\ntransform = Compose([\n    Resize((128, 128)),  \n    ToTensor(),\n    Normalize(mean=[0.5], std=[0.5])\n])\n\n# Tải và tiền xử lý ảnh\ninfected_img = Image.open(infected_image_path).convert('L')\ninfected_img = transform(infected_img).unsqueeze(0).to(device)\n\n# Khởi tạo và tải mô hình\ngenerator = UNetGenerator(in_channels=1, out_channels=1).to(device)\ngenerator.load_state_dict(torch.load(weights_path, map_location=device))\ngenerator.eval()\n\n# Phục hồi ảnh\nwith torch.no_grad():\n    restored_img = generator(infected_img)\n\nsave_and_display_images(infected_img, restored_img, infected_image_path, output_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T11:28:02.3032Z","iopub.execute_input":"2025-05-26T11:28:02.303479Z","iopub.status.idle":"2025-05-26T11:28:02.62564Z","shell.execute_reply.started":"2025-05-26T11:28:02.303457Z","shell.execute_reply":"2025-05-26T11:28:02.62482Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}