{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11855604,"sourceType":"datasetVersion","datasetId":7449507},{"sourceId":11899594,"sourceType":"datasetVersion","datasetId":7480228}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MRI Slice-based GAN\n\nThis notebook implements a DCGAN model for generating synthetic 2D MRI slices from 3D MRI volumes.\n\n## Steps:\n1. Install required packages\n2. Load and preprocess 3D MRI data\n3. Extract middle slices from 3D volumes\n4. Train the DCGAN model\n5. Generate new MRI images","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport torchvision.utils as vutils\n\n# Set random seeds for reproducibility\nrandom_seed = 42\ntorch.manual_seed(random_seed)\ntorch.cuda.manual_seed(random_seed)\nnp.random.seed(random_seed)\nrandom.seed(random_seed)\n\n# Check if CUDA is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T12:33:39.684289Z","iopub.execute_input":"2025-05-21T12:33:39.685093Z","iopub.status.idle":"2025-05-21T12:33:46.730106Z","shell.execute_reply.started":"2025-05-21T12:33:39.685062Z","shell.execute_reply":"2025-05-21T12:33:46.729471Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dataset class for MRI slices\nclass MRISliceDataset(Dataset):\n    def __init__(self, image_dir, transform=None):\n        self.image_dir = image_dir\n        self.transform = transform\n        \n        # Lấy tất cả file ảnh PNG hoặc JPG trong thư mục\n        self.image_paths = [os.path.join(image_dir, fname) \n                            for fname in os.listdir(image_dir) \n                            if fname.lower().endswith(('.png', '.jpg', '.jpeg'))]\n        \n        print(f\"Loaded {len(self.image_paths)} 2D MRI slice images from: {image_dir}\")\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path).convert(\"L\")  # Đọc ảnh grayscale\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T12:33:46.731132Z","iopub.execute_input":"2025-05-21T12:33:46.731428Z","iopub.status.idle":"2025-05-21T12:33:46.736955Z","shell.execute_reply.started":"2025-05-21T12:33:46.73141Z","shell.execute_reply":"2025-05-21T12:33:46.73614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define weight initialization function\ndef weights_init_normal(m):\n    classname = m.__class__.__name__\n    if classname.find(\"Conv\") != -1:\n        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find(\"BatchNorm2d\") != -1:\n        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n        torch.nn.init.constant_(m.bias.data, 0.0)\n\n# Generator model\nclass Generator(nn.Module):\n    def __init__(self, latent_dim, img_size, channels=1):\n        super(Generator, self).__init__()\n\n        self.init_size = img_size // 4\n        self.latent_dim = latent_dim\n        \n        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n\n        self.conv_blocks = nn.Sequential(\n            nn.BatchNorm2d(128),\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n            nn.BatchNorm2d(128, 0.8),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n            nn.BatchNorm2d(64, 0.8),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n            nn.Tanh(),\n        )\n\n    def forward(self, z):\n        out = self.l1(z)\n        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n        img = self.conv_blocks(out)\n        return img\n\n\n# Discriminator model\nclass Discriminator(nn.Module):\n    def __init__(self, img_size, channels=1):\n        super(Discriminator, self).__init__()\n\n        def discriminator_block(in_filters, out_filters, bn=True):\n            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n            if bn:\n                block.append(nn.BatchNorm2d(out_filters, 0.8))\n            return block\n\n        self.model = nn.Sequential(\n            *discriminator_block(channels, 16, bn=False),\n            *discriminator_block(16, 32),\n            *discriminator_block(32, 64),\n            *discriminator_block(64, 128),\n        )\n\n        # The height and width of downsampled image\n        ds_size = img_size // 2 ** 4\n        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n\n    def forward(self, img):\n        out = self.model(img)\n        out = out.view(out.shape[0], -1)\n        validity = self.adv_layer(out)\n\n        return validity","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T12:33:46.737983Z","iopub.execute_input":"2025-05-21T12:33:46.738272Z","iopub.status.idle":"2025-05-21T12:33:46.759727Z","shell.execute_reply.started":"2025-05-21T12:33:46.738245Z","shell.execute_reply":"2025-05-21T12:33:46.759003Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set hyperparameters\nlatent_dim = 128\nimg_size = 128  # Resize MRI slices to this size\nbatch_size = 128\nlr = 0.0002\nb1 = 0.5\nb2 = 0.999\nn_epochs = 2500\nsample_interval = 50  # Save generated images every n epochs\n\n# Data preprocessing\ntransform = transforms.Compose([\n    transforms.Resize((img_size, img_size)),\n    transforms.Grayscale(1),  # Ensure single channel\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])  # Normalize to [-1, 1]\n])\n\n# Load the dataset\ndataset = MRISliceDataset(image_dir=\"/kaggle/input/mri-nocontrol-z-axis-dot-attack\", transform=transform)\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Initialize models\ngenerator = Generator(latent_dim=latent_dim, img_size=img_size).to(device)\ndiscriminator = Discriminator(img_size=img_size).to(device)\n\n# Initialize weights\ngenerator.apply(weights_init_normal)\ndiscriminator.apply(weights_init_normal)\n\n# Set up optimizers\noptimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\noptimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n\n# Loss function\nadversarial_loss = torch.nn.BCELoss()\n\n# Create directory for sample images\nos.makedirs(\"mri_samples\", exist_ok=True)\n\n# For visualizing training progress\nG_losses = []\nD_losses = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T12:33:46.761227Z","iopub.execute_input":"2025-05-21T12:33:46.761468Z","iopub.status.idle":"2025-05-21T12:33:47.305235Z","shell.execute_reply.started":"2025-05-21T12:33:46.761445Z","shell.execute_reply":"2025-05-21T12:33:47.304717Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training loop\nfor epoch in range(n_epochs):\n    for i, imgs in enumerate(dataloader):\n        # Configure real and fake image batch\n        real_imgs = imgs.to(device)\n        \n        # Adversarial ground truths\n        valid = torch.ones(imgs.size(0), 1, device=device)\n        fake = torch.zeros(imgs.size(0), 1, device=device)\n\n        # -----------------\n        #  Train Generator\n        # -----------------\n        optimizer_G.zero_grad()\n\n        # Sample noise as generator input\n        z = torch.randn(imgs.shape[0], latent_dim, device=device)\n\n        # Generate a batch of images\n        gen_imgs = generator(z)\n\n        # Loss measures generator's ability to fool the discriminator\n        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n\n        g_loss.backward()\n        optimizer_G.step()\n\n        # ---------------------\n        #  Train Discriminator\n        # ---------------------\n        optimizer_D.zero_grad()\n\n        # Measure discriminator's ability to classify real from generated samples\n        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n        d_loss = (real_loss + fake_loss) / 2\n\n        d_loss.backward()\n        optimizer_D.step()\n        \n        # Save losses for plotting\n        G_losses.append(g_loss.item())\n        D_losses.append(d_loss.item())\n\n    # Print progress\n    print(\n        f\"[Epoch {epoch}/{n_epochs}] \"\n        f\"[D loss: {d_loss.item():.4f}] \"\n        f\"[G loss: {g_loss.item():.4f}]\"\n    )\n\n    # Save generated samples at specified intervals\n    if epoch % sample_interval == 0:\n        # Generate and save images\n        with torch.no_grad():\n            z = torch.randn(16, latent_dim, device=device)  # Generate 16 samples\n            gen_imgs = generator(z)\n            vutils.save_image(gen_imgs.data[:16], f\"mri_samples/epoch_{epoch}.png\", \n                             normalize=True, nrow=4)\n            \n        # Also save a sample with a real MRI for comparison\n        if i == 0:  # Just use the first batch\n            comparison = torch.cat((real_imgs[:8], gen_imgs[:8]), dim=0)\n            vutils.save_image(comparison, f\"mri_samples/comparison_{epoch}.png\",\n                             normalize=True, nrow=8)\n\n# Save the trained model\ntorch.save(generator.state_dict(), \"mri_generator.pth\")\ntorch.save(discriminator.state_dict(), \"mri_discriminator.pth\")\n\n# Plot the training losses\nplt.figure(figsize=(10, 5))\nplt.title(\"Generator and Discriminator Loss During Training\")\nplt.plot(G_losses, label=\"Generator\")\nplt.plot(D_losses, label=\"Discriminator\")\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.savefig(\"mri_training_losses.png\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T12:33:47.305947Z","iopub.execute_input":"2025-05-21T12:33:47.306163Z","iopub.status.idle":"2025-05-21T16:44:14.335795Z","shell.execute_reply.started":"2025-05-21T12:33:47.306145Z","shell.execute_reply":"2025-05-21T16:44:14.334871Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_mri_samples(num_samples=16):\n    # Load the trained generator\n    trained_generator = Generator(latent_dim=latent_dim, img_size=img_size).to(device)\n    trained_generator.load_state_dict(torch.load(\"mri_generator.pth\"))\n    trained_generator.eval()\n    \n    # Generate random latent vectors\n    z = torch.randn(num_samples, latent_dim, device=device)\n    \n    # Generate images with the generator\n    with torch.no_grad():\n        generated_images = trained_generator(z)\n    \n    # Denormalize and convert to numpy for display\n    generated_images = (generated_images.detach().cpu() * 0.5 + 0.5).numpy()\n    \n    # Plot images\n    fig, axes = plt.subplots(int(np.sqrt(num_samples)), int(np.sqrt(num_samples)), figsize=(10, 10))\n    axes = axes.flatten()\n    \n    for i, img in enumerate(generated_images):\n        axes[i].imshow(img[0], cmap='gray')  # img[0] to get the first channel (grayscale)\n        axes[i].axis('off')\n    \n    plt.tight_layout()\n    plt.savefig(\"mri_generated_samples.png\", dpi=300)\n    plt.show()\n    \n    return generated_images\n\n# Generate and display new MRI samples\ngenerated_samples = generate_mri_samples(16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:11:49.685213Z","iopub.execute_input":"2025-05-21T17:11:49.68583Z","iopub.status.idle":"2025-05-21T17:11:51.690099Z","shell.execute_reply.started":"2025-05-21T17:11:49.685806Z","shell.execute_reply":"2025-05-21T17:11:51.689375Z"}},"outputs":[],"execution_count":null}]}