{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRI Slice-based GAN\n",
    "\n",
    "This notebook implements a DCGAN model for generating synthetic 2D MRI slices from 3D MRI volumes.\n",
    "\n",
    "## Steps:\n",
    "1. Install required packages\n",
    "2. Load and preprocess 2D MRI data\n",
    "3. Train the DCGAN model\n",
    "4. Generate new MRI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T12:33:39.685093Z",
     "iopub.status.busy": "2025-05-21T12:33:39.684289Z",
     "iopub.status.idle": "2025-05-21T12:33:46.730106Z",
     "shell.execute_reply": "2025-05-21T12:33:46.729471Z",
     "shell.execute_reply.started": "2025-05-21T12:33:39.685062Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T12:33:46.731428Z",
     "iopub.status.busy": "2025-05-21T12:33:46.731132Z",
     "iopub.status.idle": "2025-05-21T12:33:46.736955Z",
     "shell.execute_reply": "2025-05-21T12:33:46.73614Z",
     "shell.execute_reply.started": "2025-05-21T12:33:46.73141Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset class for MRI slices\n",
    "class MRISliceDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Lấy tất cả file ảnh PNG hoặc JPG trong thư mục\n",
    "        self.image_paths = [os.path.join(image_dir, fname) \n",
    "                            for fname in os.listdir(image_dir) \n",
    "                            if fname.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        \n",
    "        print(f\"Loaded {len(self.image_paths)} 2D MRI slice images from: {image_dir}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"L\")  # Đọc ảnh grayscale\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T12:33:46.738272Z",
     "iopub.status.busy": "2025-05-21T12:33:46.737983Z",
     "iopub.status.idle": "2025-05-21T12:33:46.759727Z",
     "shell.execute_reply": "2025-05-21T12:33:46.759003Z",
     "shell.execute_reply.started": "2025-05-21T12:33:46.738245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define weight initialization function\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "# Generator model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_size, channels=1):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.init_size = img_size // 4\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "\n",
    "# Discriminator model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_size, channels=1):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = img_size // 2 ** 4\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T12:33:46.761468Z",
     "iopub.status.busy": "2025-05-21T12:33:46.761227Z",
     "iopub.status.idle": "2025-05-21T12:33:47.305235Z",
     "shell.execute_reply": "2025-05-21T12:33:47.304717Z",
     "shell.execute_reply.started": "2025-05-21T12:33:46.761445Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "latent_dim = 128\n",
    "img_size = 128  # Resize MRI slices to this size\n",
    "batch_size = 128\n",
    "lr = 0.0002\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "n_epochs = 750\n",
    "sample_interval = 50  # Save generated images every n epochs\n",
    "\n",
    "# Data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.Grayscale(1),  # Ensure single channel\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "dataset = MRISliceDataset(image_dir=\"PATH/TO/DATA/FOLDER\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize models\n",
    "generator = Generator(latent_dim=latent_dim, img_size=img_size).to(device)\n",
    "discriminator = Discriminator(img_size=img_size).to(device)\n",
    "\n",
    "# Initialize weights\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n",
    "\n",
    "# Set up optimizers\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Create directory for sample images\n",
    "os.makedirs(\"mri_samples\", exist_ok=True)\n",
    "\n",
    "# For visualizing training progress\n",
    "G_losses = []\n",
    "D_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T12:33:47.306163Z",
     "iopub.status.busy": "2025-05-21T12:33:47.305947Z",
     "iopub.status.idle": "2025-05-21T16:44:14.335795Z",
     "shell.execute_reply": "2025-05-21T16:44:14.334871Z",
     "shell.execute_reply.started": "2025-05-21T12:33:47.306145Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    for i, imgs in enumerate(dataloader):\n",
    "        # Configure real and fake image batch\n",
    "        real_imgs = imgs.to(device)\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        valid = torch.ones(imgs.size(0), 1, device=device)\n",
    "        fake = torch.zeros(imgs.size(0), 1, device=device)\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = torch.randn(imgs.shape[0], latent_dim, device=device)\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # Save losses for plotting\n",
    "        G_losses.append(g_loss.item())\n",
    "        D_losses.append(d_loss.item())\n",
    "\n",
    "    # Print progress\n",
    "    print(\n",
    "        f\"[Epoch {epoch}/{n_epochs}] \"\n",
    "        f\"[D loss: {d_loss.item():.4f}] \"\n",
    "        f\"[G loss: {g_loss.item():.4f}]\"\n",
    "    )\n",
    "\n",
    "    # Save generated samples at specified intervals\n",
    "    if epoch % sample_interval == 0:\n",
    "        # Generate and save images\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(16, latent_dim, device=device)  # Generate 16 samples\n",
    "            gen_imgs = generator(z)\n",
    "            vutils.save_image(gen_imgs.data[:16], f\"mri_samples/epoch_{epoch}.png\", \n",
    "                             normalize=True, nrow=4)\n",
    "            \n",
    "        # Also save a sample with a real MRI for comparison\n",
    "        if i == 0:  # Just use the first batch\n",
    "            comparison = torch.cat((real_imgs[:8], gen_imgs[:8]), dim=0)\n",
    "            vutils.save_image(comparison, f\"mri_samples/comparison_{epoch}.png\",\n",
    "                             normalize=True, nrow=8)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(generator.state_dict(), \"mri_generator.pth\")\n",
    "torch.save(discriminator.state_dict(), \"mri_discriminator.pth\")\n",
    "\n",
    "# Plot the training losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses, label=\"Generator\")\n",
    "plt.plot(D_losses, label=\"Discriminator\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"mri_training_losses.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T17:11:49.68583Z",
     "iopub.status.busy": "2025-05-21T17:11:49.685213Z",
     "iopub.status.idle": "2025-05-21T17:11:51.690099Z",
     "shell.execute_reply": "2025-05-21T17:11:51.689375Z",
     "shell.execute_reply.started": "2025-05-21T17:11:49.685806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_mri_samples(num_samples=16):\n",
    "    # Load the trained generator\n",
    "    trained_generator = Generator(latent_dim=latent_dim, img_size=img_size).to(device)\n",
    "    trained_generator.load_state_dict(torch.load(\"mri_generator.pth\"))\n",
    "    trained_generator.eval()\n",
    "    \n",
    "    # Generate random latent vectors\n",
    "    z = torch.randn(num_samples, latent_dim, device=device)\n",
    "    \n",
    "    # Generate images with the generator\n",
    "    with torch.no_grad():\n",
    "        generated_images = trained_generator(z)\n",
    "    \n",
    "    # Denormalize and convert to numpy for display\n",
    "    generated_images = (generated_images.detach().cpu() * 0.5 + 0.5).numpy()\n",
    "    \n",
    "    # Plot images\n",
    "    fig, axes = plt.subplots(int(np.sqrt(num_samples)), int(np.sqrt(num_samples)), figsize=(10, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, img in enumerate(generated_images):\n",
    "        axes[i].imshow(img[0], cmap='gray')  # img[0] to get the first channel (grayscale)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"mri_generated_samples.png\", dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    return generated_images\n",
    "\n",
    "# Generate and display new MRI samples\n",
    "generated_samples = generate_mri_samples(16)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7449507,
     "sourceId": 11855604,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7480228,
     "sourceId": 11899594,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
