{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRI Image Generation using Least Squares GAN (LSGAN)\n",
    "\n",
    "This notebook trains an LSGAN model on middle sagittal slices extracted from 3D MRI volumes to generate new, synthetic MRI images.\n",
    "\n",
    "## Overview\n",
    "1. Install required packages\n",
    "2. Load and preprocess 3D MRI data\n",
    "3. Extract middle slices from 3D volumes\n",
    "4. Train LSGAN model\n",
    "5. Generate new MRI images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install nibabel\n",
    "!pip install matplotlib\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T09:38:36.586560Z",
     "iopub.status.busy": "2025-05-18T09:38:36.586204Z",
     "iopub.status.idle": "2025-05-18T09:38:45.385664Z",
     "shell.execute_reply": "2025-05-18T09:38:45.384851Z",
     "shell.execute_reply.started": "2025-05-18T09:38:36.586526Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform  # Properly import skimage.transform\n",
    "from glob import glob\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check if CUDA is available\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Create directories for saving results\n",
    "os.makedirs(\"mri_images\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "batch_size = 64\n",
    "lr = 0.0002\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "latent_dim = 128\n",
    "n_epochs = 500\n",
    "img_size = 128  # Resize MRI slices to this size\n",
    "channels = 1  # Grayscale images\n",
    "sample_interval = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T09:39:02.485131Z",
     "iopub.status.busy": "2025-05-18T09:39:02.484588Z",
     "iopub.status.idle": "2025-05-18T09:39:02.894399Z",
     "shell.execute_reply": "2025-05-18T09:39:02.893721Z",
     "shell.execute_reply.started": "2025-05-18T09:39:02.485109Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.image_paths = sorted(glob(os.path.join(data_dir, \"*.png\")))\n",
    "        self.transform = transform\n",
    "        \n",
    "        print(f\"Found {len(self.image_paths)} PNG slices\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "        \n",
    "# Define transforms: convert to tensor & normalize to [-1, 1]\n",
    "data_transform = transforms.Compose([\n",
    "    # transforms.Resize((128, 128)),  # Resize if needed\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = MRIDataset(data_dir=\"PATH/TO/DATA/FOLDER\", transform=data_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Display a sample\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if len(dataset) > 0:\n",
    "    sample_slice = dataset[0].squeeze().numpy()\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(sample_slice, cmap='gray')\n",
    "    plt.title('Sample Coronal Slice (Y-axis)')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data found!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Generator and Discriminator Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T09:39:11.215887Z",
     "iopub.status.busy": "2025-05-18T09:39:11.215245Z",
     "iopub.status.idle": "2025-05-18T09:39:11.225669Z",
     "shell.execute_reply": "2025-05-18T09:39:11.224798Z",
     "shell.execute_reply.started": "2025-05-18T09:39:11.215864Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.init_size = img_size // 4\n",
    "        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = img_size // 2 ** 4\n",
    "        self.adv_layer = nn.Linear(128 * ds_size ** 2, 1)\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Models and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T09:39:51.356609Z",
     "iopub.status.busy": "2025-05-18T09:39:51.356050Z",
     "iopub.status.idle": "2025-05-18T09:39:51.529774Z",
     "shell.execute_reply": "2025-05-18T09:39:51.528970Z",
     "shell.execute_reply.started": "2025-05-18T09:39:51.356585Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Move models to GPU if available\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "\n",
    "# Initialize weights\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n",
    "\n",
    "# Define loss function (least squares loss)\n",
    "adversarial_loss = torch.nn.MSELoss()\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "# For easier GPU handling\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "def save_model_checkpoint(model, filename):\n",
    "    \"\"\"Save model checkpoint\"\"\"\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    print(f\"Model saved to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T09:39:56.432176Z",
     "iopub.status.busy": "2025-05-18T09:39:56.431687Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to visualize generated images during training\n",
    "def visualize_generator_output(generator, fixed_noise, epoch, batches_done):\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        gen_imgs = generator(fixed_noise)\n",
    "        # Rescale from [-1, 1] to [0, 1]\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        # Save grid of generated images\n",
    "        save_image(gen_imgs.data[:25], f\"mri_images/epoch_{epoch}_batch_{batches_done}.png\", nrow=5, normalize=False)\n",
    "        \n",
    "        # Display images\n",
    "        if batches_done % (sample_interval * 5) == 0:\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(make_grid(gen_imgs[:25], nrow=5).cpu().numpy().transpose(1, 2, 0), cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"Generated MRI Images (Epoch {epoch}, Batch {batches_done})\")\n",
    "            plt.show()\n",
    "    generator.train()\n",
    "\n",
    "# Create fixed noise vector for visualization\n",
    "fixed_noise = Variable(Tensor(np.random.normal(0, 1, (25, latent_dim))))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    for i, real_imgs in enumerate(dataloader):\n",
    "        # Configure input\n",
    "        real_imgs = Variable(real_imgs.type(Tensor))\n",
    "        batch_size = real_imgs.shape[0]\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(batch_size, 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (batch_size, latent_dim))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # Calculate generator loss (LSGAN)\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = 0.5 * (real_loss + fake_loss)\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Print progress\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if i % 10 == 0:\n",
    "            print(\n",
    "                f\"[Epoch {epoch}/{n_epochs}] [Batch {i}/{len(dataloader)}] \"\n",
    "                f\"[D loss: {d_loss.item():.6f}] [G loss: {g_loss.item():.6f}]\"\n",
    "            )\n",
    "\n",
    "        # Visualize generator output\n",
    "        if batches_done % sample_interval == 0:\n",
    "            visualize_generator_output(generator, fixed_noise, epoch, batches_done)\n",
    "    \n",
    "    # Save model checkpoints at the end of each epoch\n",
    "    if epoch % 10 == 0:\n",
    "        save_model_checkpoint(generator, f\"models/generator_epoch_{epoch}.pt\")\n",
    "        save_model_checkpoint(discriminator, f\"models/discriminator_epoch_{epoch}.pt\")\n",
    "\n",
    "# Save final models\n",
    "save_model_checkpoint(generator, \"models/generator_final.pt\")\n",
    "save_model_checkpoint(discriminator, \"models/discriminator_final.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate New MRI Images (Inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T08:14:25.255029Z",
     "iopub.status.busy": "2025-05-18T08:14:25.25423Z",
     "iopub.status.idle": "2025-05-18T08:14:25.957237Z",
     "shell.execute_reply": "2025-05-18T08:14:25.9565Z",
     "shell.execute_reply.started": "2025-05-18T08:14:25.255002Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_new_mri_images(generator, num_images=10, latent_dim=128):\n",
    "    \"\"\"Generate new MRI images using the trained generator\"\"\"\n",
    "    # Set model to evaluation mode\n",
    "    generator.eval()\n",
    "    \n",
    "    # Create random noise vectors\n",
    "    noise = Variable(Tensor(np.random.normal(0, 1, (num_images, latent_dim))))\n",
    "    \n",
    "    # Generate images\n",
    "    with torch.no_grad():\n",
    "        generated_images = generator(noise)\n",
    "        # Rescale from [-1, 1] to [0, 1]\n",
    "        generated_images = 0.5 * generated_images + 0.5\n",
    "    \n",
    "    # Plot generated images\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(generated_images[i].cpu().squeeze().numpy(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Generated MRI #{i+1}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the generated images\n",
    "    save_image(generated_images, \"mri_images/final_generated_samples.png\", nrow=5, normalize=False)\n",
    "    \n",
    "    return generated_images\n",
    "\n",
    "# Generate new MRI images\n",
    "generated_samples = generate_new_mri_images(generator, num_images=10)\n",
    "print(\"MRI Generation Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Inference with Saved Model (For Future Use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T08:14:29.900188Z",
     "iopub.status.busy": "2025-05-18T08:14:29.899493Z",
     "iopub.status.idle": "2025-05-18T08:14:30.998751Z",
     "shell.execute_reply": "2025-05-18T08:14:30.998027Z",
     "shell.execute_reply.started": "2025-05-18T08:14:29.900161Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_generator_and_infer(model_path, num_images=5):\n",
    "    \"\"\"Load a saved generator model and use it to generate new MRI images\"\"\"\n",
    "    # Initialize a new generator\n",
    "    loaded_generator = Generator()\n",
    "    \n",
    "    # Load the saved parameters\n",
    "    loaded_generator.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    # Move to appropriate device\n",
    "    if cuda:\n",
    "        loaded_generator.cuda()\n",
    "    \n",
    "    # Generate images\n",
    "    generated_samples = generate_new_mri_images(loaded_generator, num_images, latent_dim)\n",
    "    \n",
    "    return generated_samples\n",
    "\n",
    "# Example usage (commented out - use this after training is complete)\n",
    "generated_samples = load_generator_and_infer(\"models/generator_final.pt\", num_images=10)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7449507,
     "sourceId": 11855604,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
